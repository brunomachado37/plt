# Stratégies
  
## Intelligence aléatoire  
  
  A son tour, le joueur actif peut effectuer l’une des 4 actions principales possibles (jouer une tuile, jouer/déplacer un leader, jouer une catastrophe ou piocher des tuiles). Pour mettre en œuvre cette stratégie, nous avons simplement attribué une probabilité à chaque action. Chaque fois que l’IA joue, elle choisira l’une des 4 actions au hasard, selon la probabilité associée.  
   
  Pour jouer une tuile, un leader ou une catastrophe, nous balayons le tableau pour vérifier toutes les positions disponibles pour l’action donnée et on en prend une aléatoirement. Nous choisissons également quelle tuile / leader à jouer, parmi ceux disponibles pour le joueur, au hasard. Pour l’action de piocher des tuiles, nous sélectionnons d’abord au hasard combien de tuiles seront changées et ensuite lesquelles.  
  
  Les 3 autres actions (construire un monument, jouer une attaque ou jouer une défense) doivent être jouées sur demande. Lorsque l’une de ces actions est demandée, nous choisissons le nombre de supporters (pour l’attaque/défense) ou le monument à construire au hasard.  


## Intelligence basée sur des heuristiques  
  
  Pour mettre en œuvre une stratégie qui fonctionnera mieux que la stratégie aléatoire, nous mettons en œuvre une intelligence basée sur l’heuristique, un ensemble de règles qui orienteront les choix de l’IA. Afin d’obtenir un score élevé, un joueur doit marquer dans tous les 4 domaines, ce qui signifie avoir des points distribués dans les 4 couleurs.  

  Pour y parvenir, nous commençons par sélectionner la couleur où le joueur a le moins de points. Si le leader de cette couleur est sur la main du joueur, l’IA doit alors jouer ce leader. La position du leader repose sur la force qu’il aura dans cette position. Par conséquent, l’IA jouera le leader dans une région sur laquelle il y a la plus grande quantité de tuiles de la couleur du leader, mais en évitant les conflits avec d’autres leaders de la même couleur. Dans le cas de l’agriculteur, il sera joué à côté d’une rivière, car les fermes ne peuvent être jouées que sur les rivières. Si plusieurs régions présentent les mêmes conditions, l’une d’elles est choisie au hasard.  
  
  Si le leader est déjà sur le plateau, si l’IA peut, elle jouera une tuile de la même couleur sur la région sur laquelle le leader est. S’il y a plus d’un poste possible dans la région de leader, l’un d’eux sera choisi au hasard.  

  Dans le cas où le joueur n’a pas une tuile de la couleur correspondante dans sa main pour jouer, tout le processus de décision est répété pour la deuxième couleur où le joueur possède le moins de points. Si ce n’est pas possible de jouer un leader ou tuile de cette couleur non plus, l’IA va alors piocher une nouvelle main.  

  Comme les catastrophes sont vraiment spécifiques (un joueur ne peut jouer que 2 fois dans un match) et n’ont pas de contexte clair sur lequel elles devraient être jouées, cette IA ne les jouera jamais.  

  Pour l’action de construction de monument et d’attaque, la même stratégie a été gardée de l’IA aléatoire. Le monument sera toujours construit si possible et l’attaque ajoutera le nombre maximum de supporters disponibles. Par contre, pour la défense, l'IA vérifiera le nombre de supporters dont elle a besoin pour gagner le conflit. Si le joueur a ce nombre de tuiles à défausser, il le fera, gagnant ainsi le conflit. Si la victoire n'est pas possible, l'IA ne se défaussera pas d'une seule tuile.  
  
##  Intelligence avancée

  Pour implémenter notre intelligence avancée, nous avons commencé par implémenter une version adaptée de minimax. Le premier changement que nous avons mis en œuvre était dû au fait qu’un joueur joue 2 fois à son tour. Cela signifie que l’algorithme va maximiser/minimiser 2 fois de suite (max, max, min, min, max ...). Afin d’optimiser l’algorithme, nous avons implémenté la version de minimax avec coupure alpha/beta.  

  Afin d’effectuer l’exploration de l’arbre, nous avons également implémenté une méthode "rollback" dans le moteur de jeu, nous permettant d’annuler la dernière action, en revenant à l’état de jeu précédent. Cela nous permet de limiter la mémoire nécessaire pour exécuter l’algorithme.  

  La première limite que nous avons rencontrée pour cette stratégie est le long temps d’exécution pour trouver chaque action. Ce problème découle de la complexité du jeu. Au début du jeu, il y a environ 700 actions différentes possibles pour chaque joueur à chaque tour. Compte tenu de la complexité de l’algorithme ( O(b d / 2) ) même pour explorer dans une petite profondeur, le facteur de ramification est beaucoup trop grand.  

  Nous avons essayé de mettre en œuvre seulement des actions qui "font sens" (les tuiles ne seront jouées que dans les régions, etc), en fonction de la façon dont les joueurs jouent habituellement. Nous pourrions réduire le nombre d’actions possibles à environ 200. Même si, le facteur de ramification encore trop grand pour être viable.  

  Par conséquent, nous avons dû trouver une autre solution pour mettre en œuvre notre intelligence avancée. Notre solution était de mélanger l’intelligence heuristique avec l’algorithme minimax.  

  L'intelligence artificielle fonctionnera comme heuristique, mais en utilisant minimax pour choisir parmi toutes les positions possibles dans la région du leader lors du jeu d’une tuile. Cette stratégie est limitée, en ce sens qu’elle ne regarde pas toutes les actions possibles, mais elle augmentera la performance par rapport à l’intelligence heuristique, considérant que plusieurs tours à venir permettront à l’IA de choisir une position pour la tuile qui favorise la construction de monuments, l’acquisition de trésors et s’engager dans des guerres sur lesquelles il sortira victorieux.  
  
  Pour valider le fonctionnement de notre IA, nous avons effectué 100 parties entre une IA avancée et une IA heuristique. L’IA avancée a remporté 57 fois. Même si la performance de notre IA avancée n’est pas vraiment supérieure à l’heuristique, nous étions satisfaits du résultat, compte tenu de la complexité du jeu.   

  Pour comparaison, le jeu de Go a un facteur de ramification moyen de 250. Il est bien connu que pour implémenter une IA performante pour le jeu de Go (comme AlphaGo) il est nécessaire d’utiliser des techniques d’apprentissage profond. Par conséquent, nous croyons que pour obtenir une IA vraiment performante sur notre projet, nous devrions utiliser des stratégies similaires (e.g. former un réseau neuronal pour évaluer un état de jeu et utiliser cette évaluation pour mettre en œuvre minimax).  
  
  
[Retour à la table des matières](../Rapport.md)